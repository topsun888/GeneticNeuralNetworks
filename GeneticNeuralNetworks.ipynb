{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Optimized by Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, feedforward neural networks are optimized by backpropagation method, to get the derivatives of weights and biases, and optimize them during each iteration of sotchastic gradient descending. However, there are alternatives for backpropagation methods, such as genetic algorithms which can search for optimal parameters using iterations of populations and generations.\n",
    "\n",
    "The genetic algorithm can generate a large population of specified neural networks with different parameters, each neural network with a specific parameter combinations is an individual. Then through calculation of fitnesses, cross-over, mutations, the algorithm tries to evolve the population in terms of the fitness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to compute feedforward propagation given input and weights, it is quite easy to initialize them. And with different parameters, we can initialize different neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize weights and biases according to uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initializeWeights(layers):\n",
    "    if type(layers) is not list:\n",
    "        print('Wrong input!')\n",
    "        return None\n",
    "    layers_num = len(layers)\n",
    "    weights = []\n",
    "    for l in range(layers_num-1):\n",
    "        weight = np.random.uniform(low=-0.01, high=0.01, size=(layers[l], layers[l+1]))\n",
    "        weights.append(weight)\n",
    "    return weights\n",
    "\n",
    "def initializeBiases(layers):\n",
    "    if type(layers) is not list:\n",
    "        print('Wrong input!')\n",
    "        return None\n",
    "    layers_num = len(layers)\n",
    "    biases = []\n",
    "    for l in range(layers_num-1):\n",
    "        bias = np.random.uniform(low=-0.01, high=0.01, size=(layers[l+1]))\n",
    "        biases.append(bias)\n",
    "    return biases\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class feedforwardnetwork:\n",
    "    '''\n",
    "    Args:\n",
    "    input_data: input matrix,[batch_size X feature_num], array\n",
    "    input_labels: one-hot labels, array\n",
    "    weights: define the weights, list\n",
    "    biases: define the biases, list\n",
    "    '''\n",
    "    def __init__(self, input_data, input_labels, weights, biases):\n",
    "        self.input_data = input_data\n",
    "        self.input_labels = input_labels\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "        \n",
    "    #Define sigmoid function\n",
    "    def sigmoid(self, Z):\n",
    "        return 1/(1 + np.exp(-Z))\n",
    "    \n",
    "    #Calculate the accuracy\n",
    "    def calAccuracy(self, y, y_test):\n",
    "        '''Calculate Accuracy'''\n",
    "        return np.mean(y==y_test)\n",
    "    \n",
    "    #Create a function to do predictions\n",
    "    #Map a one-hot vector to a number\n",
    "    def vec2num(self, data, label_num=10):\n",
    "        '''Make predictions'''\n",
    "        if len(data.shape) < 2:\n",
    "            print('The input has too few dimensions')\n",
    "            return None\n",
    "        #Select the class which has largest probability\n",
    "        predictions = [(z.argmax()+ 1)%label_num for z in data]    \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def costFuncWithReg(self, h, lambda1=0.01):\n",
    "        '''\n",
    "        Calculate the cost of neural network\n",
    "        Note here we use cross entropy\n",
    "        Regularization is also taken into account\n",
    "        '''\n",
    "        y = self.input_labels\n",
    "        if h is None or y is None or self.weights is None:\n",
    "            print('Invalid Input!')\n",
    "            return None\n",
    "        sample_num = len(y)#Length of y\n",
    "        #Cost of errors\n",
    "        total = -np.mean(np.sum(y*np.log(h), axis=1))\n",
    "        #Cost of regularization\n",
    "        weights = np.array(self.weights)\n",
    "        reg = 0\n",
    "        for wgt in weights:\n",
    "            reg += np.sum(wgt**2) * lambda1/2/sample_num\n",
    "        total +=  reg    \n",
    "        return total \n",
    "    \n",
    "    def proceed(self):\n",
    "        '''\n",
    "        Finish the procedure of feed forward network \n",
    "        and calculate the output\n",
    "        '''\n",
    "        h, output_h, input_z = self.feedforwardNeuralNetwork()\n",
    "        labels = self.vec2num(self.input_labels)\n",
    "        predictions = self.vec2num(h)\n",
    "        #self.fitness = self.costFuncWithReg(h)\n",
    "        self.accuracy = self.calAccuracy(labels, predictions)\n",
    "        self.fitness = self.accuracy\n",
    "        \n",
    "    def update(self, new_weights, new_biases):\n",
    "        '''\n",
    "        Update weights and biases\n",
    "        '''\n",
    "        self.weights = new_weights\n",
    "        self.biases = new_biases\n",
    "    \n",
    "    #weights: weights for each layer, a list\n",
    "    def feedforwardNeuralNetwork(self):\n",
    "        '''Calculate feedforward propagation output'''\n",
    "        ######Deal with extreme cases###\n",
    "        X = self.input_data\n",
    "        if X is None or self.weights is None:\n",
    "            print('Invalid Input!')\n",
    "            return None\n",
    "        dim = X.shape\n",
    "        if len(dim) < 2:\n",
    "            print('X has too less variables')\n",
    "            return None\n",
    "        #####Define variables###########\n",
    "        layer_num = len(self.weights)\n",
    "        output_h = []#Output for each layer\n",
    "        output_h.append(X)#The first layer is equal to input X\n",
    "        input_z = []#Input for each layer, starts from the second layer\n",
    "        #####Make alculations for each layer, except the input layer\n",
    "        for i in range(layer_num):\n",
    "            z = np.dot(output_h[i], self.weights[i])\n",
    "            z += self.biases[i]\n",
    "            h = self.sigmoid(z)\n",
    "            output_h.append(h)\n",
    "            input_z.append(z)\n",
    "        return h, output_h, input_z    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = [784, 128, 10]\n",
    "weights = initializeWeights(layers)\n",
    "biases = initializeBiases(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_images, batch_labels = mnist.train.images, mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw = feedforwardnetwork(batch_images, batch_labels, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing:1.211\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "fw.proceed()\n",
    "end = time()\n",
    "print('Timing:{:.3f}'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes much time to finish computation for each individual. So it must be time-consuming if we have a large population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.098490909090909087"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw.fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fw.update(weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fw.proceed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.098490909090909087"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw.fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an feedforward object, we can create an instance of neural network by specifying the parameters. We can also create a population of neural networks with different parameters. How to generate the parameters, that's a question we will answer by genetic algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Create population\n",
    "\n",
    "In this project, we can view the parameters of neural networks as genes, our goal is to find optimal genes, namely   parameters that make those neural networks performance well on predictions.\n",
    "There are four major steps in a genetic algorithm:\n",
    "- Create Population, randomly create parameters and generate neural networks according to the parameters\n",
    "- Calculate fitness, calculate the fitness of each individual neural network\n",
    "- Cross over, according to the fitness, select some individuals as parents, and cross over their genes to make children\n",
    "- Mutate, select certain individual neural networks and make mutations on their parameters(genes)\n",
    "\n",
    "Update the older generation during each iteration, for more information please visit: https://en.wikipedia.org/wiki/Genetic_algorithm ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create a group of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class initPopulation:\n",
    "    def __init__(self, layers, pop_size=100):\n",
    "        '''\n",
    "        Args:\n",
    "        pop_size: number of population, integer\n",
    "        layers: neuron number for each layer, list\n",
    "        '''\n",
    "        self.pop_size = pop_size\n",
    "        self.layers = layers\n",
    "        \n",
    "    def __initializeWeights__(self):\n",
    "        '''\n",
    "        Initialize weights between each two neigbouring layers\n",
    "        '''\n",
    "        layers = self.layers\n",
    "        if type(layers) is not list:\n",
    "            print('Wrong input!')\n",
    "            return None\n",
    "        layers_num = len(layers)\n",
    "        weights = []\n",
    "        for l in range(layers_num-1):\n",
    "            weight = np.random.uniform(low=-0.01, high=0.01, size=(layers[l], layers[l+1]))\n",
    "            weights.append(weight)\n",
    "        return weights\n",
    "\n",
    "    def __initializeBiases__(self):\n",
    "        '''\n",
    "        Initialize biases for each layer(except for input layer)\n",
    "        '''\n",
    "        layers = self.layers\n",
    "        if type(layers) is not list:\n",
    "            print('Wrong input!')\n",
    "            return None\n",
    "        layers_num = len(layers)\n",
    "        biases = []\n",
    "        for l in range(layers_num-1):\n",
    "            bias = np.random.uniform(low=-0.01, high=0.01, size=(layers[l+1]))\n",
    "            biases.append(bias)\n",
    "        return biases\n",
    "    \n",
    "    def generatePop(self):\n",
    "        '''\n",
    "        Generate a group of weights at random\n",
    "        '''\n",
    "        population = []\n",
    "        for i in range(self.pop_size):\n",
    "            weights = self.__initializeWeights__()\n",
    "            biases = self.__initializeBiases__()\n",
    "            #Initialize an individual\n",
    "            individual = feedforwardnetwork(batch_images, batch_labels, weights, biases)\n",
    "            #Calculate fitness\n",
    "            individual.proceed()\n",
    "            population.append(individual)\n",
    "        return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop = initPopulation(layers)\n",
    "population = pop.generatePop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.Genetic Algorithm\n",
    "\n",
    "In this part, we are going to realize selection, crossover and mutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import  copy\n",
    "class GA:\n",
    "    def __init__(self, population):\n",
    "        '''\n",
    "        Initialize genetic algorithm\n",
    "        '''\n",
    "        self.population = population\n",
    "        \n",
    "    def select(self, ratio=0.3):\n",
    "        '''\n",
    "        Randomly select part of original population\n",
    "        '''\n",
    "        #Get the fitness for each individual\n",
    "        fitnesses = [one.fitness for one in iter(self.population)]\n",
    "        fitnesses.insert(0, 0)\n",
    "        #Calculate the sum of the fitness\n",
    "        total_fitness = np.sum(fitnesses)\n",
    "        #Normalization\n",
    "        fitnesses = np.array(fitnesses)/total_fitness\n",
    "        #Accumulated sum\n",
    "        probs = np.cumsum(fitnesses)\n",
    "        select_num = int(ratio * len(self.population))\n",
    "        select_pop_index = []\n",
    "        #Select a parent according to its fitness value\n",
    "        for _ in np.arange(select_num):\n",
    "            p = np.random.uniform(0, 1)\n",
    "            for i in np.arange(len(probs)-1):\n",
    "                if (p<=probs[i+1]) & (p>probs[i]):\n",
    "                    select_pop_index.append(i)\n",
    "                    break\n",
    "        return select_pop_index\n",
    "        \n",
    "    def crossover(self, parent1, parent2):\n",
    "        '''\n",
    "        Cross over the genes of parents and\n",
    "        Generate children\n",
    "        Args:\n",
    "        parent1: individual object\n",
    "        parent2: individual object\n",
    "        '''\n",
    "        weights1, weights2 = parent1.weights, parent2.weights\n",
    "        biases1, biases2 = parent1.biases, parent2.biases\n",
    "        new_weights1, new_weights2 = copy.deepcopy(weights1), copy.deepcopy(weights2)\n",
    "        new_biases1, new_biases2 = copy.deepcopy(biases1), copy.deepcopy(biases2)\n",
    "        weight_num = len(weights1)\n",
    "        select_layer = np.random.choice(weight_num)\n",
    "        weight_shape =  weights2[select_layer].shape\n",
    "        row = np.random.choice(weight_shape[0])\n",
    "        col = np.random.choice(weight_shape[1])\n",
    "        #Swap the specified weights\n",
    "        new_weights1[select_layer][row:, :col] = weights2[select_layer][row:, :col]\n",
    "        new_weights2[select_layer][row:, :col] = weights1[select_layer][row:, :col]\n",
    "        #Swap the specified biases\n",
    "        biases_num = len(biases1)\n",
    "        select_layer = np.random.choice(biases_num)\n",
    "        #biase_shape =  len(biases2[selet_layer])\n",
    "        #point = np.random.choice(biase_shape)\n",
    "        new_biases1[select_layer] = biases2[select_layer]\n",
    "        new_biases2[select_layer] = biases1[select_layer]\n",
    "        #Update the weights and biases\n",
    "        parent1.update(new_weights1, new_biases1)\n",
    "        parent2.update(new_weights2, new_biases2)\n",
    "        parent1.proceed()\n",
    "        parent2.proceed()\n",
    "        return parent1, parent2\n",
    "    \n",
    "    def mutation(self, individual):\n",
    "        '''\n",
    "        Mutation at several random point within an individual\n",
    "        '''\n",
    "        weights, biases = individual.weights, individual.biases\n",
    "        #Mutate weights\n",
    "        for i in np.arange(len(weights)):\n",
    "            shape = weights[i].shape\n",
    "            for _ in range(3):\n",
    "                row = np.random.choice(shape[0])\n",
    "                col = np.random.choice(shape[1])\n",
    "                weights[i][row, col] = np.random.uniform(-0.01, 0.01)\n",
    "        for i in np.arange(len(biases)):\n",
    "            point = np.random.choice(len(biases[i]))\n",
    "            biases[i][point] = np.random.uniform(-0.01, 0.01)\n",
    "        individual.update(weights, biases)\n",
    "        individual.proceed()\n",
    "        return individual\n",
    "        \n",
    "    def proceed(self):\n",
    "        '''\n",
    "        Execute crossover and mutation\n",
    "        '''\n",
    "        select_pop_index = self.select()\n",
    "        #Keep the best individual\n",
    "        _, optimal_index = self.findMaximalIndividual()\n",
    "        best_individual = self.population[optimal_index]\n",
    "        #cross over\n",
    "        pair_num = int(len(select_pop_index)/2)\n",
    "        for i in np.arange(pair_num):\n",
    "            parent1, parent2 = self.population[i], self.population[i+pair_num]\n",
    "            child1, child2 = self.crossover(parent1, parent2)\n",
    "            self.population[i], self.population[i+pair_num] = child1, child2\n",
    "            \n",
    "        #mutation\n",
    "        for i in np.arange(3):\n",
    "            index = np.random.choice(len(self.population))\n",
    "            individual = self.population[index]\n",
    "            self.population[index] = self.mutation(individual)\n",
    "        #Keep the best individual\n",
    "        self.population[optimal_index] = best_individual\n",
    "        #return self.population\n",
    "        \n",
    "    def findMaximalIndividual(self):\n",
    "        accuracies = np.array([one.accuracy for one in self.population])\n",
    "        fitnesses = np.array([one.fitness for one in self.population])\n",
    "        optimal_value = max(fitnesses)\n",
    "        optimal_index = fitnesses.argmax()\n",
    "        return optimal_value, optimal_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ga = GA(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Try 20 generations\n",
    "for _ in range(100):\n",
    "    ga.proceed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09916363636363637, 5)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga.findMaximalIndividual()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not satisfying as the population is not large and generations is not sufficient to search in the weights space. Backpropation method works much effective because they know how to find optimal direction. Perhaps io"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
